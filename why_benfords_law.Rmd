---
title: "Why Benford's law is approximately correct for any distribution that smoothly covers several orders of magnitude"
author: "Corey Yanofsky"
date: "11/29/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

[Benford's law](https://en.wikipedia.org/wiki/Benford%27s_law) is the name given to the peculiar empirical observation that in many natural data sets (particularly ones spanning many orders of magnitude) the relative frequency of the _first_ digit of each data point is not uniform but rather equal to $$log_{10}\left(d + 1\right) - log_{10}\left(d\right) = log_{10}\left(1 + \frac{1}{d}\right),$$ for $d \in \{1,2,...,9\}$.

### Frequency of digits from uniformly distributed logarithms

The Wikipedia article linked above states

> Benford's law is sometimes stated in a stronger form, asserting that the fractional part of the logarithm of data is typically close to uniformly distributed between 0 and 1; from this, the main claim about the distribution of first digits can be derived.

Why the fractional part of the logarithm? When we take the leading digit of a number we're saying that the order of magnitude doesn't matter; 20 (whose logarithm base 10 is 1.3) is equivalent to 200 (log base 10 equals 2.3) and 2,000 (log base 10 equals 3.3) when it comes to the first digit.

We can basically derive the "main claim" from this stronger form of Benford's law with one graph:

```{r plot, echo = FALSE}

plot(c(0.9, 11 + 1/9), c(0,1), type = "n", log = "x", xlab = "x", ylab = "", yaxt = "n", frame.plot = FALSE)
axis(1, at = 1:10)
lines(c(1,1), c(0,1))
lines(c(1,10), c(1,1))
lines(c(10,10), c(0,1))
for(i in 2:9) lines(c(i,i), c(0,1), lty = 2)


```

If we take a random variable $X$ that is uniformly distributed between 0 and 1 and define $Y = 10^X$ then values of $Y$ with leading digit 1 fall between the tick marks for 1 and 2, values of $Y$ with leading digit 2 fall between the tick marks for 2 and 3, and so on.  

So the question becomes: why does the stronger form of Benford's law hold approximately for any distribution that smoothly covers several orders of magnitude? Well, it comes down to the fundamental theorem of calculus.

### Yep, the good ol' fundamental theorem of calculus

As discussed above, the distribution of the first digit (or of the first two digits or what have you) of a random variable $Y$ is entirely determined by the distribution of the fractional part of the random variable $X = \log_{10}Y$. The fractional part is defined as $W = X - \lfloor X\rfloor$ where $\lfloor\cdot\rfloor$ is the floor function; given a probability density $f(x)$, the density of the fractional part is
$$ g\left(w\right) = \sum_{k=-\infty}^{\infty}f\left(k+w\right), w\in[0,1).$$
What this equation says is that we take every interval lying between each pair of consecutive whole numbers and layer all of the density there on the interval between 0 and 1. Now, because we're limiting our attention to distributions that smoothly cover several orders of magnitude, we can approximate the density in each interval by a first order Taylor series approximation centered at the middle of each interval:
$$g\left(w\right) = \sum_{k=-\infty}^{\infty}\left[f\left(k+\frac{1}{2}\right) + \left(w - \frac{1}{2}\right) f^{\prime}\left(k+\frac{1}{2}\right)\right], w\in[0,1).$$
This sum of linear functions is again linear, with slope given by
$$g^{\prime}\left(w\right) = \sum_{k=-\infty}^{\infty}f^{\prime}\left(k+\frac{1}{2}\right)\approx\int_{-\infty}^{\infty}f^{\prime}\left(x\right)\mathrm{d}x.$$
The fundamental theorem of calculus tells us
$$\int_{-\infty}^{\infty}f^{\prime}\left(x\right)\mathrm{d}x=\lim_{x\rightarrow+\infty}f\left(x\right) - \lim_{x\rightarrow-\infty}f\left(x\right) $$

Smooth densities start at zero off at $x\rightarrow-\infty$, go up, maybe wiggle around a bit (but not too much -- smooth!) and then back down to zero at $x\rightarrow+\infty$. So to a good approximation, $g\left(w\right)$ is a linear function between 0 and 1 with slope 0 -- that is to say, it's a uniform distribution. 